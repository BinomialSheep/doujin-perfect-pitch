# 同人ダメ絶対音感AI ver1.00

2024年5月11日

## Abstract

音声ファイルからどのDLsite声優の声か識別するAIシステム「同人ダメ絶対音感AI」を設計・実装し、精度を評価しました。
本レポートの時点では特徴量としてMFCC、学習手法としてExtra treesを用いています。

73声優を識別するモデルの現在の正答率は47.8%です。また、予想上位5人まで正解とした場合は74.1%、確信度0.3以上に限定した正解率は85.2%であり、適用サービス次第では実用可能な精度は出ていると考えます。

一方で、この先の大きな精度向上について、学習データ量やパラメータチューニングに留まらない、特徴量抽出の抜本的な改善案についても検討しました。

## Introduction

コンピュータを用いて音声から話者を特定する技術は、音声処理ではポピュラーな分野です。古典的には数理モデルベースのアプローチが使われてきましたが、現代では機械学習ベースの先行研究が多数あり、信号処理の深い知識を持たない在野のITエンジニアでも扱えるようになってきました。Qiitaにも音声コーパスを使用して100人の話者を識別する機械学習システムを作成する記事[^1]があり、今回大いに参考にしました。

話者認識には発話者分離、声紋認証など様々な応用があります。
エンタメ分野でも「このナレーションの声優は誰か」「この声優と似た声の声優が知りたい」というのは自然な欲求で、検索するとアニメ声優を対象としたアプリがいくつか見つかります。事前登録開始記事[^2]のみであったりレビューの評価低かったりするので、精度高い既存システムがあるのか知りませんが。一方で、DLsite声優を対象にした既存サービスは見つかりません。自分はDLsite声優やネット活動者の声を識別できるシステムの方が欲しいので、作ろうというのがモチベーションです。

なお、本システムで使用しているAI技術は、特定人物の声を再現して発話することも可能な生成AI技術とは異なるものであり、パブリシティ権を侵害するような悪用はできないことを付記しておきます。


## Methods

### 訓練データの収集
今回はDLsite音声作品の体験版ファイルを利用します。
Webスクレイピングし、作品ページ掲載のzipファイルもしくはchobit音声をダウンロードしました。

DLsiteには2024年4月現在、5万本弱の音声作品あります。今回は新着作品から17000作品をチェックし、うち12086作品の体験版計41652ファイルを収集しました。
使用していない作品は、体験版未掲載、声優未掲載、声優2人以上の作品か、あるいは何らかのエラーでダウンロードに失敗した作品です。

### 特徴量
音声ファイルから抽出する特徴量には、12次元のMFCC（メル周波数ケプストラム係数）を用います。
MFCCは人間の音声知覚を考慮した声道特性の係数であり、音声認識分野で昔からとてもよく使われています。12次元というのもスタンダードっぽです。

ざっくり言うと、音声から抽出したい非自明な指標の代表として、「どんな言葉を喋っているか（音源の特性）」「誰が喋っているか（声道の特性）」があって、これは音声波形の「激しい振動（高周波数成分）」「緩やかな振動（低周波数成分）」に対応するらしいです。ということでフーリエ変換して周波数領域に移してから、人間の音声知覚を考慮しつつ低周波数をフィルターすれば、声道特性が分かりそうですねという感じです。

他に自明な関心としては声の大きさや高さがあり、非自明な関心としては感情推定とか音源方向の推定とかがあると思います、知らんけど。
技術的な話はググれば色々出てきます[^3]が、今回はこのパートはlibrosa[^4]という便利なライブラリを貼るだけなので省略します。


### 学習手法

特徴量抽出後に、PyCaretというAutoMLライブラリで予測モデルを選定します。

選ばれたのはExtra Trees Classifierでした。
正式名称Extremely Randomized Treesからも分かるように、決定木学習や、それをアンサンブル学習にしたランダムフォレストの派生です。高速な学習が可能かつ少ないデータでも過学習しにくく、雑に使ってもいい感じになる学習手法として知られています。


## Results & Discussion

本レポートでは断りがない限り、同一声優のファイルが100ファイル以上収集できたファイルを学習対象としています。
73声優で計24549ファイル分のデータがdataフォルダのmfcc_17000_mte100.csvに収録されています。
20240511_fulldataに生データが含まれている他、本リポジトリのコードを動かすことで再現可能です（実行ごとに若干の変動はあります）

| Accuracy | AUC    | Recall | Prec.  | F1     | Kappa  | MCC    | 声優数 | 学習データ数合計 |
| -------- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ---------------- |
| 0.4777   | 0.9098 | 0.4777 | 0.5097 | 0.4509 | 0.4582 | 0.4609 | 73     | 24549            |

こちらがテストデータに対する現時点の性能です。
ある音声を聴いて、その声優が73声優のどの声優か分類するというタスクを行い、47.8%の確率で当てられることを表しています。

機械学習用語の詳しい説明は割愛します。1が最大で、1に近いほど良いです。

- Accuracy (正確度)：全予測の中で正しく予測された割合
- AUC ：Area Under the Curve。判別能の高さ
- Recall (再現率)：実際の正の例のうち、正しく正と予測された割合
- Precision (適合率)：正と予測されたデータの中で、実際に正であるデータの割合
- F1 Score (F1スコア)：PrecisionとRecallの調和平均。
- Kappa ：カッパ統計量。ランダムな一致を除外してくれている指標
- MCC ：Matthews Correlation Coefficient。-1から1で、0がランダム予測、1は完全予測


### 要求ファイル数, 識別クラス数と精度について
| 声優あたりファイル数    | Accuracy | AUC    | Recall | Prec.  | F1     | Kappa  | MCC    | 声優数 | 学習データ数合計 |
| ----------------------- | -------- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ---------------- |
| 10ファイル以上          | 0.3814   | 0.8704 | 0.3814 | 0.3838 | 0.3388 | 0.3688 | 0.371  | 509    | 37384            |
| 40ファイル以上          | 0.4194   | 0.8938 | 0.4194 | 0.4428 | 0.3859 | 0.4042 | 0.407  | 186    | 31302            |
| 100ファイル以上（標準） | 0.4777   | 0.9098 | 0.4777 | 0.5097 | 0.4509 | 0.4582 | 0.4609 | 73     | 24549            |
| 200ファイル以上         | 0.5265   | 0.9171 | 0.5265 | 0.5491 | 0.505  | 0.5012 | 0.5038 | 35     | 5738             |


「1声優あたり100ファイル以上ある声優のみ学習対象」という基準を変えて評価したのが上記テーブルです。要求ファイル数を大きくするほど、学習に使える情報が増え、また対象となる声優の選択肢が減ることで簡単になるので、精度は上がります。
しかし509声優を38.1%識別するのは結構スゴい気がしますが、35声優を52.7%識別するのはあまり嬉しくないですし、訓練データの用意が大変になります。
当面は100ファイル100声優の精度向上に努めることにします。

ところで同一手法（MFCC＋PyCrat）でスゴくキレイな同規模のデータセット（各声優が同じ100個のセリフを読み上げた音声集）を使用すると、100人の判定に対して98.6%の精度が出るようです。[^1]
本システムの学習データは体験版からかき集めた音声であることや、同じ声優でも演技の方向性の差が特徴量に表れている可能性があること、そして水音などを分離できておらず純粋な声で学習できていないのが精度の差に現れていると考えています。

### 訓練データ数による精度の向上余地
| 訓練データ割合 | Accuracy | AUC    | Recall | Prec.  | F1     | Kappa  | MCC    |
| -------------- | -------- | ------ | ------ | ------ | ------ | ------ | ------ |
| 0.1            | 0.3416   | 0.845  | 0.3416 | 0.3455 | 0.3083 | 0.3153 | 0.3182 |
| 0.2            | 0.4269   | 0.889  | 0.4269 | 0.4505 | 0.3961 | 0.4051 | 0.4079 |
| 0.7（標準）    | 0.4777   | 0.9098 | 0.4777 | 0.5097 | 0.4509 | 0.4582 | 0.4609 |
| 0.9            | 0.5022   | 0.9202 | 0.5022 | 0.5405 | 0.476  | 0.4837 | 0.4867 |

訓練データ数が増えると精度はどの程度上がるのか、という実験です。訓練データとテストデータの割合を変えて実験しています。
まだデータ数がサチっていないようで、訓練データ数を増やすと性能が顕著に上がっていきます。

現在使用しているのはDLsite体験版音声の1/3程度なので、収集データを増やすだけでも精度向上の余地はあります。
声優はDLsiteの全期間に渡って活動しているわけではないため全体験版を収集しても1人あたりのデータ数は単純に3倍にはなりませんが、製品版音声や音声ファイル分割で訓練データ数を増やすこともでき、学習データ量を増やすだけで正答率が60%以上に達する可能性もありそうです。

一方で前節で述べたように、理想的には現在のデータ数でほぼ100%の精度のモデルが作れることは分かっており、データの量を増やすよりも質を改善するフェーズと考えています。

なお、訓練データ割合は他の評価では常に0.7を採用していますが、これは機械学習における一般的な割合で、PyCaretでもデフォルト値です。


### 予測上位N件に入っていれば正解とする場合

| 上位N件   | 正解率 | 声優数 |
| --------- | ------ | ------ |
| 1（標準） | 0.4777 | 73     |
| 2         | 0.5999 | 73     |
| 3         | 0.6687 | 73     |
| 4         | 0.7084 | 73     |
| 5         | 0.7408 | 73     |
| 6         | 0.7703 | 73     |
| 7         | 0.7882 | 73     |
| 8         | 0.8073 | 73     |
| 9         | 0.8224 | 73     |
| 10        | 0.8356 | 73     |

システムの応用範囲次第では、オーディオファイルの声優を正確に当てる必要はありません。
「誰の声か分からないから知りたい」という目的であれば5人くらいまで候補を絞ることができればあとは自分で調べられそうです。
「この声に似た声優を発掘したい」という目的であればむしろ候補が何人も出てきた方が嬉しいでしょう。
逆に能登麻美子と早見沙織をAIに聞き分けてほしい場合は厳密に誰の声か特定する精度が必要になります。

このように「何人か候補を出して、その中に正解がいればＯＫ」と緩和した場合の精度を調べました。
緩和するごとに顕著に正解率が上がっていますね。

| 上位N件 | 正解率 | 声優数 |
| ------- | ------ | ------ |
| 1       | 0.3812 | 507    |
| 2       | 0.4669 | 507    |
| 3       | 0.524  | 507    |
| 4       | 0.5619 | 507    |
| 5       | 0.5918 | 507    |
| 6       | 0.6126 | 507    |
| 7       | 0.6294 | 507    |
| 8       | 0.6476 | 507    |
| 9       | 0.6636 | 507    |
| 10      | 0.6757 | 507    |

こちらは「1声優あたり10ファイル以上あれば学習対象」の条件で同様の集計を行ったテーブルです。少ないファイルから学習する必要がある上、識別する必要があるクラスが507もあり難度が高いのですが、正解判定を緩和することで、適用サービス次第では十分役立つ正解率になっています。


| target     | TopN_Classes                               | TopN_Scores        |
| ---------- | ------------------------------------------ | ------------------ |
| 氷上のあ   | [氷上のあ, 御子柴泉, 柚木つばめ]           | [0.31, 0.09, 0.07] |
| 陽向葵ゅか | [陽向葵ゅか, 柚木つばめ, 水野七海]         | [0.31, 0.22, 0.08] |
| 秋野かえで | [秋野かえで, 乙倉ゅい(乙倉由依), 御子柴泉] | [0.16, 0.14, 0.13] |
| 高梨はなみ | [山田じぇみ子, 柚木つばめ, 高梨はなみ]     | [0.25, 0.23, 0.06] |
| 秋山はるる | [柚木つばめ, 涼花みなせ, 逢坂成美]         | [0.14, 0.11, 0.1]  |
| STELLA     | [STELLA, 分倍河原シホ, 姫宮ぬく美]         | [0.09, 0.09, 0.08] |
...
| 早緒きむり   |  [早緒きむり, 逢坂成美, 星野天]              |  [0.21, 0.1, 0.08] |

ちなみに生出力をこんな感じに加工して出力させた上で集計しています。

### 確信度が閾値超の予測のみ対象とする場合
| 確信度閾値  | 正解率 | 声優数 | テストデータ数 |
| ----------- | ------ | ------ | -------------- |
| 0.0（標準） | 0.4777 | 73     | 7365           |
| 0.1         | 0.4912 | 73     | 7084           |
| 0.2         | 0.6963 | 73     | 3685           |
| 0.3         | 0.8516 | 69     | 1927           |
| 0.4         | 0.9466 | 63     | 1104           |
| 0.5         | 0.9816 | 57     | 706            |
| 0.6         | 0.9864 | 55     | 514            |
| 0.7         | 0.9928 | 48     | 415            |
| 0.8         | 0.9912 | 43     | 341            |
| 0.9         | 0.9897 | 41     | 292            |
| 1.0         | 0.9848 | 28     | 197            |

クラス分類タスクでは各予測について、確信度のようなスコアを出すことができます。前節のTopN_Scores列のようにです。
この表は、確信度が一定以上の予測に限定して正解率を集計した表です。そうであってほしいように、AIの確信度が高いほど正解率が高いことが分かります。

確信度は、典型的には二値分類で「偽陽性と偽陰性どちらが嫌か」によって陽性閾値を変える時などに役立ちます。
多値分類でも、前節の複数回答と合わせて「出力にどの程度の確信度を持っているか」は適用アプリケーション次第でユーザーの参考になります。

また、「半分くらいのデータに対しては正解率70%程度の確信を持っていて、一方で95%正解するほど確信を持っているデータは全体の15%くらいしかないのか」というのも精度改善する上で価値のある情報そうです。


| 声優       | 閾値 | precision | recall   | f1-score | support |
| ---------- | ---- | --------- | -------- | -------- | ------- |
| こやまはる | 0.0  | 0.500000  | 0.205479 | 0.291262 | 73      |
| こやまはる | 0.1  | 0.500000  | 0.206349 | 0.292135 | 63      |
| こやまはる | 0.2  | 0.750000  | 0.142857 | 0.240000 | 21      |
| こやまはる | 0.3  | 0.000000  | 0.000000 | 0.000000 | 6       |

確信度が上がるとなぜか精度が下がっている謎のケース。


## Conclusion
本システムは現在、73声優を47.8%の正解率で識別することができ、特に予想上位5人まで正解とした場合は74.1%の正解率です。
「体験版の音源を前処理なしで使用し、ドメインを考慮せず標準的な特徴量を使い、機械学習手法もAutoMLにお任せ」という段階で既に、ある種の応用が可能な精度に達しており、有効なアプローチであったと考えています。
一方で声優クラスを増やすと（当然ながら）正解率が落ちることも分かり、ネットという無数の声雄が割拠する世界から最新最強の武器バイノーラルマイクを駆使しファンのみんなに癒しと感動を与える声優すべてを十分な精度で識別するAIを目指すのであれば、こちらも最新最強のテクノロジーを駆使してまずは精度改善に取り組む必要があります。
そのためのネクストアクションについてはFuture Workで議論します。

## Future Work

### ボイスのみ抽出

現在は体験版からダウンロードしたファイルをそのまま使用しているため、ボイス以外にもSEや水音などが盛大に入っています。
これにより精度に相当の悪影響を及ぼしている可能性があると考えています。
まずはSEあり、なしの音声ファイルを用意し精度を比較して、仮説検証を行いたいです。

なお、Demucsという音源分離ライブラリが音楽ファイルではキレイにボーカルと演奏を分離してくれるので試してみましたが、音声作品ではSE音を消すことはできませんでした。
音源分離技術は巨大分野であり、既存ライブラリを流用できる期待があり、サーベイしたいところです[^5][^6]。場合によっては音声作品用の音源分離AIシステムを構築する必要があるかもしれませんが。
いずれにせよ、まずは実際にSEなしの音声ファイルを用いて精度を計測するのが第一歩目です。

### 同一声優の整理
```SELECT VOICE_ACTOR, COUNT(*), SUM(DURATION) FROM AUDIO_INFO WHERE VOICE_ACTOR LIKE '%乙倉%' GROUP BY VOICE_ACTOR```
| VOICE_ACTOR          | COUNT(*) | SUM(DURATION) |
| -------------------- | -------- | ------------- |
| 乙倉ゅい             | 87       | 13828         |
| 乙倉ゅい(乙倉由依)   | 194      | 38715         |
| 乙倉ゅい（乙倉由依） | 122      | 20089         |

| speaker              | precision | recall   | f1-score | support |
| -------------------- | --------- | -------- | -------- | ------- |
| 乙倉ゅい(乙倉由依)   | 0.727273  | 0.137931 | 0.231884 | 58.0    |
| 乙倉ゅい（乙倉由依） | 0.750000  | 0.081081 | 0.146341 | 37.0    |


表記ゆれや名義分けにより、同一声優が別々の声優として集計されている場合、精度悪化や学習データ不足になり得ます。
例えば乙倉ゅいさんは表記ゆれで3つに分かれており、うち2つが100ファイル以上のため、AIは別々の声優として学習しています。
このような場合、precisionやrecallは大きく悪化し、理論的には最大でも0.5になってしまうはずです。（precisionが0.5を大きく超えているのは、声道以外の何らかの特徴を学習していしまっている可能性がありますね）

実際に統一してから再度モデルを作成したところ、精度が大きく改善しました。

| speaker            | precision | recall   | f1-score | support |
| ------------------ | --------- | -------- | -------- | ------- |
| 乙倉ゅい(乙倉由依) | 0.851852  | 0.242105 | 0.377049 | 95.0    |


表記ゆれをある程度機械的に検出しながら、名義分けを手動で統一することで、改善が期待できます。

なお、逆に同一名称の別声優が混在している可能性もあります、DLsite上も区別されておらず識別のためには別の機械学習タスクが必要となり、具体的に精度に影響を与えそうな同一名称も思い当たらないため、費用対効果が悪いと考えています。


### 深層学習

自然な発展として、流行のイケイケディープラーニング手法でポンして精度が上がらないかというのは気になります。
ただしMFCCはディープラーニングの特徴量には向いていないことが知られている[^7]ため、異なる特徴量抽出手法を実装する必要があります。頑張ります。


### フロントエンドの作成

本システムのありそうな社会還元として、「ファイルをアップロードしたら、サーバ側で予測が行われて、予想声優が画面に表示される」Webシステムの構築があります。
この場合、通信量的にもモラル的にも、クライアント側で特徴量抽出を行って、サーバには特徴量のみを送信するシステムにすべきです。
そうすると、現在Libsoraに任せている特徴量抽出を自前で実装することになるというのが一番の難所です。
Libsoraの当該コードはある程度読みましたが、窓関数などすべてJavaScriptで再実装するのは結構面倒なので、学習モデル構築の時点でLibsoraでなく自作の（PythonとJavaScriptで同じ値を出力させることができる）特徴量抽出関数を作成しておく方があとあと良さそうです。

## Appendix
### 手法比較
mfcc_17000_mte100.csvの場合

| Model                           | Abbreviation | Accuracy | AUC    | Recall | Prec.  | F1     | Kappa  | MCC    | TT (Sec) |
| ------------------------------- | ------------ | -------- | ------ | ------ | ------ | ------ | ------ | ------ | -------- |
| Extra Trees Classifier          | ET           | 0.4682   | 0.9073 | 0.4682 | 0.4925 | 0.4383 | 0.4484 | 0.4511 | 0.788    |
| Random Forest Classifier        | RF           | 0.4559   | 0.9035 | 0.4559 | 0.4708 | 0.4249 | 0.4360 | 0.4382 | 0.737    |
| Quadratic Discriminant Analysis | QDA          | 0.4511   | 0.9170 | 0.4511 | 0.4519 | 0.4361 | 0.4342 | 0.4352 | 0.060    |
| Light Gradient Boosting Machine | LightGBM     | 0.4369   | 0.9184 | 0.4369 | 0.4445 | 0.4150 | 0.4164 | 0.4182 | 48.209   |
| Logistic Regression             | LR           | 0.3745   | 0.8967 | 0.3745 | 0.3512 | 0.3458 | 0.3523 | 0.3538 | 15.070   |
| K Neighbors Classifier          | KNN          | 0.3676   | 0.7846 | 0.3676 | 0.3904 | 0.3603 | 0.3497 | 0.3503 | 0.178    |
| Linear Discriminant Analysis    | LDA          | 0.3655   | 0.8904 | 0.3655 | 0.3480 | 0.3321 | 0.3422 | 0.3444 | 0.040    |
| Decision Tree Classifier        | DT           | 0.2421   | 0.6112 | 0.2421 | 0.2438 | 0.2408 | 0.2216 | 0.2217 | 0.490    |
| Naive Bayes                     | NB           | 0.2402   | 0.8100 | 0.2402 | 0.2589 | 0.2102 | 0.2193 | 0.2225 | 0.047    |
| Ridge Classifier                | Ridge        | 0.2285   | 0.0000 | 0.2285 | 0.1825 | 0.1468 | 0.1851 | 0.1967 | 0.026    |
| SVM - Linear Kernel             | SVM          | 0.1703   | 0.0000 | 0.1703 | 0.2627 | 0.1448 | 0.1432 | 0.1578 | 0.321    |
| Ada Boost Classifier            | Ad           | 0.1189   | 0.6330 | 0.1189 | 0.0683 | 0.0680 | 0.0808 | 0.0857 | 4.159    |
| Dummy Classifier                | Dummy        | 0.0742   | 0.5000 | 0.0742 | 0.0055 | 0.0103 | 0.0000 | 0.0000 | 0.028    |


### 声優ごとの精度
mfcc_17000_mte100.csvの場合
| speaker              | precision | recall   | f1-score | support |
| -------------------- | --------- | -------- | -------- | ------- |
| はらぺこちゃん       | 0.938931  | 0.866197 | 0.901099 | 142.0   |
| 鈴戯原えるる         | 0.875000  | 0.840000 | 0.857143 | 50.0    |
| 架月らみゅ           | 0.857143  | 0.727273 | 0.786885 | 33.0    |
| 口谷亜夜             | 0.785714  | 0.733333 | 0.758621 | 30.0    |
| STELLA               | 0.641509  | 0.871795 | 0.739130 | 39.0    |
| 七瀬ゆな             | 0.630435  | 0.828571 | 0.716049 | 35.0    |
| 小机永遠             | 0.595420  | 0.886364 | 0.712329 | 88.0    |
| 鳴先そら             | 0.700000  | 0.625000 | 0.660377 | 56.0    |
| 氷上のあ             | 0.670330  | 0.603960 | 0.635417 | 101.0   |
| 神間みと             | 0.652174  | 0.612245 | 0.631579 | 49.0    |
| 園宮さつき           | 0.492958  | 0.875000 | 0.630631 | 40.0    |
| 竹早芽衣             | 0.645161  | 0.606061 | 0.625000 | 33.0    |
| 千種蒼               | 0.625000  | 0.595238 | 0.609756 | 42.0    |
| 伊ヶ崎綾香           | 0.654321  | 0.569892 | 0.609195 | 93.0    |
| 来夢ふらん           | 0.720930  | 0.525424 | 0.607843 | 59.0    |
| 小鳥遊いと           | 0.647059  | 0.568966 | 0.605505 | 58.0    |
| 蘭世                 | 0.544304  | 0.651515 | 0.593103 | 66.0    |
| 大山チロル           | 0.521186  | 0.627551 | 0.569444 | 196.0   |
| みもりあいの         | 0.575540  | 0.555556 | 0.565371 | 144.0   |
| 早緒きむり           | 0.414737  | 0.784861 | 0.542700 | 251.0   |
| 恋鈴桃歌             | 0.575758  | 0.503311 | 0.537102 | 151.0   |
| もとき　りお         | 0.809524  | 0.386364 | 0.523077 | 44.0    |
| 涼花みなせ           | 0.490421  | 0.554113 | 0.520325 | 231.0   |
| 陽向葵ゅか           | 0.394913  | 0.714286 | 0.508621 | 413.0   |
| 御子柴泉             | 0.383895  | 0.749543 | 0.507740 | 547.0   |
| 柚木つばめ           | 0.416252  | 0.650259 | 0.507583 | 386.0   |
| 山田じぇみ子         | 0.476190  | 0.537634 | 0.505051 | 186.0   |
| 姫宮ぬく美           | 0.789474  | 0.365854 | 0.500000 | 41.0    |
| 涼貴涼               | 0.529412  | 0.466667 | 0.496063 | 135.0   |
| 秋野かえで           | 0.396341  | 0.598160 | 0.476773 | 326.0   |
| 星丸ななか           | 0.600000  | 0.387097 | 0.470588 | 31.0    |
| 麦咲輪紫葵           | 0.622222  | 0.368421 | 0.462810 | 76.0    |
| 藤村莉央             | 0.434783  | 0.473684 | 0.453401 | 190.0   |
| weighted avg         | 0.509736  | 0.477665 | 0.450911 | 7365.0  |
| 夢咲みるく           | 0.409836  | 0.490196 | 0.446429 | 102.0   |
| 秋山はるる           | 0.500000  | 0.377483 | 0.430189 | 151.0   |
| ありがた～い私       | 0.571429  | 0.344828 | 0.430108 | 58.0    |
| macro avg            | 0.573853  | 0.395107 | 0.423355 | 7365.0  |
| 浪実みお             | 0.647059  | 0.305556 | 0.415094 | 36.0    |
| 星野天               | 0.692308  | 0.295082 | 0.413793 | 61.0    |
| 餅梨あむ             | 0.399240  | 0.426829 | 0.412574 | 246.0   |
| 兎月りりむ。         | 0.833333  | 0.263158 | 0.400000 | 38.0    |
| 分倍河原シホ         | 0.437500  | 0.347518 | 0.387352 | 141.0   |
| 夏目ミカコ           | 0.562500  | 0.290323 | 0.382979 | 31.0    |
| 都みみち             | 0.484375  | 0.303922 | 0.373494 | 102.0   |
| 杏仁らいち           | 0.666667  | 0.250000 | 0.363636 | 48.0    |
| 沢野ぽぷら           | 0.750000  | 0.226415 | 0.347826 | 53.0    |
| 逢坂成美             | 0.375000  | 0.312500 | 0.340909 | 240.0   |
| 双葉すずね           | 0.555556  | 0.238095 | 0.333333 | 42.0    |
| 水野七海             | 0.562500  | 0.209302 | 0.305085 | 43.0    |
| 神代そら             | 0.451613  | 0.225806 | 0.301075 | 124.0   |
| 彩夢ひな             | 0.666667  | 0.193548 | 0.300000 | 31.0    |
| 篠守ゆきこ           | 0.481481  | 0.213115 | 0.295455 | 61.0    |
| まあ油るる           | 0.483871  | 0.211268 | 0.294118 | 71.0    |
| 西瓜すいか           | 0.465753  | 0.213836 | 0.293103 | 159.0   |
| 夢咲めぇ             | 0.666667  | 0.187500 | 0.292683 | 32.0    |
| 桜音のん             | 0.600000  | 0.193548 | 0.292683 | 31.0    |
| こやまはる           | 0.500000  | 0.205479 | 0.291262 | 73.0    |
| 海音ミヅチ           | 0.558140  | 0.190476 | 0.284024 | 126.0   |
| 堀米玲音             | 0.714286  | 0.147059 | 0.243902 | 34.0    |
| 一之瀬りと           | 0.400000  | 0.166667 | 0.235294 | 36.0    |
| 乙倉ゅい(乙倉由依)   | 0.727273  | 0.137931 | 0.231884 | 58.0    |
| 眠音りま             | 0.571429  | 0.137931 | 0.222222 | 58.0    |
| 琴音有波             | 0.615385  | 0.133333 | 0.219178 | 60.0    |
| 田中                 | 0.545455  | 0.133333 | 0.214286 | 45.0    |
| 浅木式               | 0.500000  | 0.135593 | 0.213333 | 118.0   |
| 天知遥               | 0.555556  | 0.131579 | 0.212766 | 76.0    |
| MOMOKA。             | 0.500000  | 0.120879 | 0.194690 | 91.0    |
| そらまめ。           | 0.500000  | 0.096154 | 0.161290 | 52.0    |
| 乙倉ゅい（乙倉由依） | 0.750000  | 0.081081 | 0.146341 | 37.0    |
| 花咲椿姫             | 0.666667  | 0.057143 | 0.105263 | 35.0    |
| ありのりあ           | 0.500000  | 0.054054 | 0.097561 | 37.0    |
| 高梨はなみ           | 0.333333  | 0.040000 | 0.071429 | 75.0    |
| 咲坂栞               | 0.333333  | 0.023256 | 0.043478 | 43.0    |
| 野上菜月             | 0.250000  | 0.020833 | 0.038462 | 48.0    |

### 実装上の面倒ポイント（データ収集）

#### DLsite音声作品
DLsiteには作品IDがあるのですが、これは全ジャンルの作品で一意なため100万以上あり、一方で現時点の音声作品は5万程度です。まず検索結果などから全ての音声作品の作品IDを取得することで、データ収集時間とDLsiteへの負荷を大幅に減らすことが出来ます。

#### 体験版ダウンロード
体験版は、zipファイルまたはchobitを埋め込む形で各作品ページに掲載されています。
chobitの場合は1度のhtml取得では音声のurlが分からないので、まずchobitのリンク先を取得して、次にchobitにアクセスして音声ファイルをダウンロードしていました。

なお、chobitは動画ファイルのことがあります。その場合はsubprocessでffmpegを呼び出してmp3でダウンロードしましたが、数は多くないので無視でもいいと思います。

#### zip解凍

様々な環境で作られたzipファイルがあり、罠が多いです。

まず文字化け関連です。
Pythonのzipfileライブラリを使用するのですが、windowsの標準機能で日本語ファイル名を圧縮したzipの場合は文字化けします。
これは有名で、一度cp437でエンコードしてcp932でデコードする手法が知られています。たまに失敗するので、その場合は文字化けしたファイル名のまま扱います（ファイル名は本システムで重要でないので）。
ただしフォルダ名が文字化けしていると困ることがあるので、zipからファイル1つ1つを直接解凍してdownloadディレクトリ直下に放り込むなどの処理をすると良いです。

また、Macの標準圧縮の場合は、MACOSXフォルダのメタデータが残ったままの場合があります。メタデータは「.（ファイル名）.wav」というように音声ファイルの拡張子で、ファイル名を拡張子でしか判定していないとLibrosaに投げたタイミングで実行時例外を吐きます。適当にメタデータは除外しましょう。

他には、Deflate64という形式でzip圧縮している作品もありました。これはライセンスの都合上zipfileで扱えないので、subprocessで7zを呼び出して解凍します。また、エラー率の問題なのかDeflateなのにzipfileやwindows標準では解凍できず、7zでは解凍できるzipも1つだけありました。謎ですが、困ったら7zを呼び出すことにしています。7zip最高！




## References

[^1]: 【Python】声優100人をキレイに話者識別するための機械学習レシピ(https://qiita.com/adumaru0828/items/a95de3a0fbfe54f51953)

[^2]: 声を聞かせるだけで声優の名前と作品が分かる 「ANIVO｜アニボ」の事前登録を開始(https://prtimes.jp/main/html/rd/p/000001179.000002302.html)

[^3]: 人工知能に関する断創録 メル周波数ケプストラム係数（MFCC）(https://aidiary.hatenablog.com/entry/20120225/1330179868)

[^4]: librosa(https://libosa.org/doc/latest/index.html)

[^5]: 音源分離技術の基礎と応用～音源分離ﾁｮｯﾄﾜｶﾙになるための手引き～(https://www.docswell.com/s/d-kitamura/ZQ898R-20230624)

[^6]: Pythonで学ぶ音源分離（機械学習実践シリーズ）, 戸上真人, (https://book.impress.co.jp/books/1119101154)

[^7]: Deep Learning for Audio Signal Processing, CoRR, May 2019(https://arxiv.org/abs/1905.00078)